{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Processing data with pandas II\n",
    "\n",
    "Finnish university students are encouraged to use the CSC Noppe platform.<br/>\n",
    "<a href=\"https://noppe.csc.fi/\"><img alt=\"CSC badge\" src=\"https://img.shields.io/badge/launch-CSC%20Noppe-blue.svg\" style=\"vertical-align:text-bottom\"></a>\n",
    "\n",
    "**Note** :We do not recommended using Binder for this lesson.\n",
    "\n",
    "This week we will continue developing our skills using [pandas](https://pandas.pydata.org/) to process real data. \n",
    "\n",
    "## Motivation\n",
    "\n",
    "![YLE news article from summer 2024](img/yle-summer-2024.png)<br/>\n",
    "*Source: [https://yle.fi/a/74-20109657](https://yle.fi/a/74-20109657)*\n",
    "\n",
    "Finland's record for the largest number of 'hot' days was broken in summer 2024 after temperatures breached the official 'heatwave' threshold of 25 degrees Celsius more than 66 times this year. The previous record of 65 hot days was reached in 2002, according to Finnish Meteorological Institute (FMI) statistics [Source: YLE](https://yle.fi/a/74-20109657).\n",
    "\n",
    "In this lesson, we will use our data manipulation and analysis skills to analyze weather data, and investigate how hot this summer has been in general in Helsinki and whether this breaking record is valid for several other cities across Finland (Helsinki, Oulu, Lappeenranta, Porvoo, Rovaniemi, and Turku). \n",
    "\n",
    "Along the way we will cover a number of useful techniques in pandas including:\n",
    "\n",
    "- renaming columns\n",
    "- iterating data frame rows and applying functions\n",
    "- data aggregation\n",
    "- repeating the analysis task for several input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Input data\n",
    "\n",
    "In the lesson this week we are using weather observation data from the [Finnish Meteorological Institute](https://en.ilmatieteenlaitos.fi). You will be working with temperature data recorded in Helsinki (Kumpula), Lappeenranta (airport), Oulu (Vihreäsaari harbor), Porvoo (Emäsalo), Rovaniemi (railway stattion), and Turku (Rajakari) between June 1st and August 31st 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Downloading the data\n",
    "\n",
    "**If you are using the CSC Noppe environment, there is no need to download the data manually**. The data can be found in the `data` directory.\n",
    "\n",
    "However, if you are working in another environment or if you are curious, the data is easily downloadable from the [Finnish Meteorological Institute's open data portal](https://en.ilmatieteenlaitos.fi/download-observations).\n",
    "\n",
    "![Finnish meteorological institute data portal](img/fmi.png)  \n",
    "*Source: [FMI Open Data Portal](https://en.ilmatieteenlaitos.fi/download-observations)*\n",
    "\n",
    "Simply choose the parameters you want in your dataset (for this lesson: Air temperature), select the correct time interval (for this lesson: Hourly), choose the aggregation method (Mean), set the time period (1.6.2024 - 31.8.2024), and select the observation station. You can then download the data in various formats. In this lesson we will use CSV files downloaded from the portal.\n",
    "\n",
    "For this lesson, we are accessing the files from the `data` directory. For simplicity, the CSV files have been renamed as follows:\n",
    "\n",
    "```\n",
    "Helsinki_Kumpula.csv\n",
    "Lappeenranta_airport.csv\n",
    "Oulu_harbour.csv\n",
    "Porvoo_Emäsalo.csv\n",
    "Rovaniemi_station.csv\n",
    "Turku_Rajakari.csv\n",
    "```\n",
    "\n",
    "Now you should be all set to proceed with the lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## About the data\n",
    "\n",
    "The CSV files have the following structure:\n",
    "\n",
    "```\n",
    "Observation station,Year,Month,Day,Time [Local time],Air temperature mean [°C],Relative humidity mean [%],Gust speed mean [m/s]\n",
    "Helsinki Kumpula,2024,6,1,00:00,19.3,69.6,1.9\n",
    "```\n",
    "\n",
    "As you can see, the columns are comma-separated. Below is a snippet showing the first row of data from the Helsinki Kumpula observation station:\n",
    "\n",
    "| Observation station | Year | Month | Day | Time [Local time] | Air temperature mean [°C] | Relative humidity mean [%] | Gust speed mean [m/s] |\n",
    "|---------------------|------|-------|-----|-------------------|---------------------------|----------------------------|-----------------------|\n",
    "| Helsinki Kumpula    | 2024 | 6     | 1   | 00:00             | 19.3                      | 69.6                       | 1.9                   |\n",
    "\n",
    "The column names are rather self-explanatory. Here’s a breakdown of what each column contains:\n",
    "\n",
    "- **Observation station**: The name of the weather station where the measurements were recorded (e.g., Helsinki Kumpula).\n",
    "- **Year**: The year in which the data was recorded.\n",
    "- **Month**: The month in which the data was recorded, represented numerically (e.g., 6 for June).\n",
    "- **Day**: The specific day of the month on which the data was recorded.\n",
    "- **Time [Local time]**: The time at which the air temperature and other variables were measured, expressed in local time using a 24-hour format.\n",
    "- **Air temperature mean [°C]**: The mean air temperature recorded at the given time, measured in degrees Celsius.\n",
    "- **Relative humidity mean [%]**: The average relative humidity at the given time, measured as a percentage.\n",
    "- **Gust speed mean [m/s]**: The mean wind gust speed at the given time, measured in meters per second.\n",
    "\n",
    "We will develop our analysis workflow using data from a single station. Then, we will repeat the same process for all the stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "In order to get started, let's first import `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can already have a quick look at the data file `Helsinki_Kumpula.csv` and how it is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative path to the file\n",
    "fp = r\"data/Helsinki_Kumpula.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data and specify the \"-\" character for NoData values\n",
    "data = pd.read_csv(fp, na_values=[\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Handling No Data Values\n",
    "\n",
    "It is common in many datasets (including others we will use later in this lesson) to encounter missing data. These missing values can be handled or represented in various ways depending on the data source. For instance, they could be encoded as arbitrary values like `-9999`, or through special symbols such as varying numbers of asterisks `*`. It's important to inspect your dataset or review the metadata to be aware of how missing values are represented. This ensures that missing data is correctly interpreted during analysis.\n",
    "\n",
    "When reading data files with `pandas`, we can use the `na_values` parameter to specify a list of values that should be treated as missing. For example, if we had a data file in which missing values were represented by varying numbers of `*` characters, we could instruct `pandas` to recognize these as `NaN` by passing the appropriate list to the `na_values` parameter (e.g., `na_values=['*', '**', '***', '****', '*****', '******']`). In addition, if the values were separated by varying numbers of spaces rather than commas we could use the parameter `delim_whitespace=True`. In that case, the data would be read as shown below.\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(\n",
    "    'datafile.csv', delim_whitespace=True, na_values=[\"*\", \"**\", \"***\", \"****\", \"*****\", \"******\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's see how the data looks by printing the first five rows with the `.head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems ok. However, we likely won't be needing all of the columns for detecting warm temperatures. We can check all column names by running `data.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting columns form pandas dataframe\n",
    "\n",
    "You can remove a column from your dataframe using `drop` method. Let's remove the columns `Relative humidity mean [%]` and `Gust speed mean [m/s]` from our dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop two columns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also drop teh columns `inplace` without needing to store it in a veriable. However, be careful with this as it will directly apply the change to your data. \n",
    "\n",
    "```\n",
    "data.drop(columns=[\"Relative humidity mean [%]\",\"Gust speed mean [m/s]\"], inplace = True)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data once again\n",
    "\n",
    "This time, we will read in only the columns using the `usecols` parameter. Let's read in the data again but this time without `Relative humidity mean [%]` and `Gust speed mean [m/s]`, which would not be useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in only selected columns\n",
    "data = pd.read_csv(\n",
    "    fp,\n",
    "    usecols=['Observation station', 'Year', 'Month', 'Day','Time [Local time]', 'Air temperature mean [°C]'])\n",
    "\n",
    "# Check the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Renaming columns\n",
    "\n",
    "As we saw above, some of the column names are a bit too long. Luckily, it is easy to alter labels in a pandas DataFrame using the [.rename()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) function. In order to change the column names, we need to tell pandas how we want to rename the columns using a dictionary that lists old and new column names\n",
    "\n",
    "Let's first check again the current column names in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can define the new column names using a [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) where we list `key: value` pairs, in which the original column name (the one which will be replaced) is the key and the new column name is the value.\n",
    "\n",
    "### Dictionaries\n",
    "\n",
    "A [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) is a specific type of data structure in Python for storing key-value pairs. In this course, we will use dictionaries mainly when renaming columns in a pandas DataFrame, but dictionaries are useful for many different purposes! For more information about Python dictionaries, check out [this tutorial](https://realpython.com/python-dicts/).\n",
    "\n",
    "Let's change the following:\n",
    "\n",
    "- `Observation station` to `STATION`\n",
    "- `Time [Local time]` to `TIME`\n",
    "- `Air temperature mean [°C]` to `TEMP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the dictionary with old and new names\n",
    "\n",
    "\n",
    "# Let's see what the variable new_names look like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the data type of the new_names variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "From above we can see that we have successfully created a new dictionary. \n",
    "\n",
    "Now we can change the column names by passing that dictionary using the parameter `columns` in the `.rename()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "\n",
    "\n",
    "# Print the new columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Perfect, now our column names are more concise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Check your understanding\n",
    "\n",
    "The temperature values in our data files are in degrees Celcius. As you might guess, we will soon convert these temperatures in to degrees Fahrenheit. In order to avoid confusion with the columns, let's rename the column `TEMP` to `TEMP_C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Create the dictionary with old and new names\n",
    "\n",
    "\n",
    "# Rename the columns\n",
    "\n",
    "\n",
    "# Check the output\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Data properties\n",
    "\n",
    "As we learned last week, it's always a good idea to check basic properties of the input data before proceeding with the data analysis. Let's check the:\n",
    "\n",
    "- Number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Top and bottom rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Data types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using your own functions in pandas \n",
    "\n",
    "Now it's again time to convert temperatures! Yes, we have already done this many times before, but this time we will learn how to apply our own functions to data in a pandas DataFrame.\n",
    "\n",
    "First, we will define a function for the temperature conversion, and then we will apply this function for each Celsius value on each row of the DataFrame. The output celsius values will be stored in a new column called `TEMP_F`.\n",
    "\n",
    "To begin we will see how we can apply the function row-by-row using a `for` loop and then we will learn how to apply the function to all rows more efficiently all at once.\n",
    "\n",
    "### Defining the function\n",
    "\n",
    "For both of these approaches, we first need to define our function to convert temperature from Celsius to Fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def celsius_to_fahr(temp_celsius):\n",
    "    \"\"\"Converts temperatures from Celsius to Fahrenheit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    temp_celsius: int | float\n",
    "        Input temperature in Celsius (should be a number)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Temperature in Fahrenheit (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the Celsius into Fahrenheit\n",
    "    converted_temp = (temp_celsius * 1.8) + 32\n",
    "\n",
    "    return converted_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure everything is working properly, let's test the function with a known value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's also print out the first rows of our data frame to see our input data before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over rows\n",
    "\n",
    "We can use the function one row at a time using a `for` loop and the [.iterrows()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html) method. This will allow us to repeat a given process *for each row in a pandas DataFrame*. Please note that iterating over rows is a rather inefficient approach, but it is still useful to understand the logic behind the iteration.\n",
    "\n",
    "When using the `.iterrows()` method it is important to understand that `.iterrows()` accesses not only the values of one row, but also the `index` of the row as well. \n",
    "\n",
    "Let's start with a simple for loop that goes through each row in our DataFrame.\n",
    "\n",
    "```{note}\n",
    "We use single quotes to select the column `TEMP_C` of the row in the example below. This is because using double quotes would result in a `SyntaxError` since Python would interpret this as the end of the string for the `print()` function.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate over the rows\n",
    "for idx, row in data.iterrows():\n",
    "\n",
    "    # Print the index value\n",
    "    print(f\"Index: {idx}\")\n",
    "\n",
    "    # Print the row\n",
    "    print(f\"Temp C: {row['TEMP_C']}\\n\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking a loop\n",
    "\n",
    "When developing code in a `for` loop, you do not always need to go through the entire loop in order to test things out. \n",
    "The [break](https://docs.python.org/3/reference/simple_stmts.html#break) statement in Python terminates the current loop whereever it is placed and we can use it here just to check out the values on the first row (based on the first iteration in the `for` loop.\n",
    "This can be helpful when working with a large data file or dataset, because you might not want to print thousands of values to the screen!\n",
    "For more information, check out [this tutorial](https://www.tutorialspoint.com/python/python_break_statement.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `idx` variable indeed contains the index value at position 0 (the first row) and the `row` variable contains all the data from that given row stored as a pandas `Series`.\n",
    "\n",
    "Let's now create an empty column `TEMP_F` for the Celsius temperatures and update the values in that column using the `celsius_to_fahr` function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty float column for the output values\n",
    "data[\"TEMP_F\"] = 0.0\n",
    "\n",
    "# Iterate over the rows\n",
    "for idx, row in data.iterrows():\n",
    "\n",
    "    # Convert the Fahrenheit to Celsius\n",
    "    temp_fahr = celsius_to_fahr(row[\"TEMP_C\"])\n",
    "\n",
    "    # Update the value of 'Celsius' column with the converted value\n",
    "    data.at[idx, \"TEMP_F\"] = temp_fahr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Reminder: `.at[]` or `.loc[]`?\n",
    "\n",
    "Here, you could also use `data.loc[idx, new_column] = temp_fahr` to achieve the same result. \n",
    "    \n",
    "If you only need to access a single value in a DataFrame, [DataFrame.at[]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html) is faster than [DataFrame.loc[]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html), which is designed for accessing groups of rows and columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how our DataFrame looks after the calculations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Applying the function\n",
    "\n",
    "Pandas DataFrames and Series have a dedicated method `.apply()` for applying functions on columns (or rows!). When using `.apply()`, we pass the function name (without parentheses!) as an argument to the `.apply()` method. Let's start by applying the function to the `TEMP_C` column, which contains the temperature values in degrees Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look logical, so it seems safe to store them permanently in the `TEMP_F` column (overwriting the old values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We can also apply the conversion function to multiple columns simultaneously while reordering the DataFrame. For instance, if our dataset contained three temperature columns (`TEMP`, `MIN`, and `MAX`), we could perform the conversion and reorganize the columns in one step, as shown below.\n",
    "\n",
    "```\n",
    "data[[\"TEMP\", \"MIN\", \"MAX\"]].apply(celsius_to_fahr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also notice that our conversion function would also allow us to pass one column or the entire DataFrame as a parameter (e.g., `celsius_to_fahrs(data[\"TEMP_C\"])`). However, the code is perhaps easier to follow when using the `.apply()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the DataFrame contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Should I use .iterrows() or .apply()?\n",
    "\n",
    "We are teaching the `.iterrows()` method because it helps you to understand the structure of a DataFrame and the process of looping through DataFrame rows. However, using `.apply()` is often far more efficient in terms of execution time. \n",
    "\n",
    "At this point, the most important thing is that you understand what happens when you are modifying the values in a pandas DataFrame. When doing the course exercises, either of these approaches is ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing dates\n",
    "\n",
    "As part of this lesson, we want to group our data by day and calculate the average daily temperatures. Currently, we have separate columns storing information on the year, month, and day. Since our data is from the summer of a single year (2024), we do not need to include the year in our grouping. However, we do need to use the information from the month and day for our analysis.\n",
    "\n",
    "Let's start by looking at the contents of these columns and their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The Month and Day columns contain integers. And as evident by the column `TIME`, several observations are made per day (every hour). We can already see the data types above, but we can check them again using `dtypes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information in this column is stored as integer values.\n",
    "\n",
    "We now want to aggregate the data on a daily level, and in order to do so we need to \"label\" each row of data based on the month and day when the record was observed. In order to do this, we need to somehow aggregate the information for month and day for each row.\n",
    "\n",
    "We can create these \"labels\" by making a new column containing information about the month and day.\n",
    "\n",
    "Before taking that step, hwever, we should first convert the contents in the `Month` and `Day` columns to character strings in two new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now that we have converted the Month and Day data into character strings, the next step is to combine the information from the `MONTH_STR` and `DAY_STR` columns into a new column called `MONTH_DAY`. We will use this format `MM-DD`.\n",
    "\n",
    "By applying the `.str.zfill(2)` method to the `DAY_STR` and `MONTH_STR` columns, we ensure that they always have two digits, even when the values are less than 10. This guarantees that the final format is always consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the two strings\n",
    "\n",
    "\n",
    "# Let's see what we have\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we have \"labeled\" the rows based on information about date, but only including the month and day in the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String slicing\n",
    "\n",
    "Date and time data can come in various formats. In some cases, your data may contain a long integer or string representing the date and time. For example, \"201910012350\" could represent 23:50 on the 1st of October, 2019. In such cases, it is useful to first convert the values to a string (as they may initially be rendered as integers) and then use the [`pandas.Series.str.slice()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.slice.html) method. For example, from the string \"201910012350\", you can extract the year and month and write them to a new column `YEAR_MONTH` as follows:\n",
    "\n",
    "```\n",
    "data[\"YEAR_MONTH\"] = data[\"TIME_STR\"].str.slice(start=0, stop=6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime (*optional*)\n",
    "\n",
    "In pandas, we can convert date and time information into a specialized data type called [datetime](https://docs.python.org/3/library/datetime.html) using the [`pandas.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) function. This allows for more efficient date and time manipulations.\n",
    "\n",
    "To start, we can create a `DATE_STR` column by concatenating the `Year`, `Month`, and `Day` columns into a single string in the format `YYYYMMDD`. We will again apply the `.str.zfill(2)` method to the `MONTH_STR` and `DAY_STR` columns to ensure the formatting is consistent for all dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"YEAR_STR\"] = data[\"Year\"].astype(str)\n",
    "# Combine the three strings\n",
    "data[\"DATE_STR\"] = data[\"YEAR_STR\"] +  data[\"MONTH_STR\"].str.zfill(2) + data[\"DAY_STR\"].str.zfill(2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert character strings to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"DATE_STR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output\n",
    "data[\"DATE\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Pandas Series datetime properties\n",
    "\n",
    "There are several methods available for accessing information about the properties of datetime values. You can read more about datetime properties [from the pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetime-properties)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new `DATE` column, we can now extract different time units using the [`pandas.Series.dt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DATE\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the datetime functionalities with other methods from pandas. For example, we can check the number of unique months in our input data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DATE\"].dt.month.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For the final analysis, we need combined information of the month and day. Here is another way we could achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract month and day from the full date (as a string in 'MM-DD' format)\n",
    "data[\"MONTH_DAY_DT\"] = data[\"DATE\"].dt.strftime(\"%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Default Year Behavior in `pd.to_datetime()`\n",
    "\n",
    "When using `pd.to_datetime()` with only month (`%m`) and day (`%d`) in the format string, pandas defaults to using the year 1900. This behavior occurs because the `datetime` module requires a full date, including a year, to function properly. Without a specified year, pandas fills in the year as 1900.\n",
    "\n",
    "If you need to represent just the month and day without the year, like we do here, we can treat the values as strings using `dt.strftime(\"%m-%d\")`. This way, we avoid the default year issue.\n",
    "\n",
    "Alternatively, if you plan to perform date-based operations, you should retain the full date and simply ignore the year in your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"MONTH_DAY_DT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we have a unique label for each DAY as a datetime object which is the same as what we made ealier without using datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"MONTH_DAY_DT\"] == data[\"MONTH_DAY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Aggregating data in pandas by grouping\n",
    "\n",
    "Here, we will learn how to use [pandas.DataFrame.groupby()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html), which is a handy method for combining large amounts of data and computing statistics for subgroups.\n",
    "\n",
    "In our case, we will use the `.groupby()` method to calculate average temperatures for each month in three steps:\n",
    "\n",
    "1. Grouping the data based on the month and day\n",
    "2. Calculating the average for each day (each group) \n",
    "3. Storing those values into a new DataFrame called `daily_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Before we start grouping the data, let's once again see what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of rows: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite a few rows of weather data, and several observations per day. Our goal is to create an aggreated data frame that would have only one row per day.\n",
    "\n",
    "To condense our data to daily average values we can group our data based on the unique month and day combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is also possible to create combinations of months and days on the fly when grouping the data:\n",
    "    \n",
    "```python\n",
    "# Group the data \n",
    "grouped = data.groupby(['Month', 'Day'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore the new variable `grouped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a new object with type `DataFrameGroupBy` with 92 groups. In order to understand what just happened, let's also check the number of unique month and day combinations in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MONTH_DAY\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of the grouped object should be the same as the number of unique values in the column we used for grouping. For each unique value, there is a group of data. This makes sense, as we have 92 days from first of June to the end of August. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore our grouped data even further. \n",
    "\n",
    "We can check the \"names\" of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Accessing data for one group\n",
    "\n",
    "Let us now check the contents for the group representing July 17th (the name of that group is `07-17`). We can get the values of that hour from the grouped object using the `.get_group()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify a day (as character string)\n",
    "\n",
    "\n",
    "# Select the group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we have\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahaa! As we can see, a single group contains a DataFrame with values only for that specific day. Let's check the data type of this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as noted above, one group is a pandas DataFrame! This is really useful, because we can now use all the familiar DataFrame methods for calculating statistics, etc. for this specific group. We can, for example, calculate the average values for all variables using the statistical functions that we have seen already (e.g. mean, std, min, max, median, etc.).\n",
    "\n",
    "Thus, we can get an average temperature for a given day using the `.mean()` function that we already did during Lesson 5. Let's calculate the mean for following attributes all at once:\n",
    "\n",
    "- `TEMP_C`\n",
    "- `TEMP_F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the columns that will be part of the calculation\n",
    "mean_cols = [\"TEMP_C\", \"TEMP_F\"]\n",
    "\n",
    "# Calculate the mean values all at one go\n",
    "\n",
    "\n",
    "# Let's see what we have\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we saw how you can access data from a single group. In order to get information about all groups (all months) we can use a `for` loop or methods available in the grouped object.\n",
    "\n",
    "### For loops and grouped objects\n",
    "\n",
    "When iterating over the groups in our `DataFrameGroupBy` object it is important to understand that a single group in our `DataFrameGroupBy` actually contains not only the actual values, but also information about the `key` that was used to do the grouping. Hence, when iterating over the data we need to assign the `key` and the values into separate variables.\n",
    "\n",
    "So, let's see how we can iterate over the groups and print the key and the data from a single group (again using `break` to only see what is happening for the first group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over groups\n",
    "for key, group in grouped:\n",
    "    # Print key and group\n",
    "    print(f\"Key:\\n {key}\")\n",
    "    print(f\"\\nFirst rows of data in this group:\\n {group.head()}\")\n",
    "\n",
    "    # Stop iteration with break command\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so from here we can see that the `key` contains the name of the group `MM-DD`.\n",
    "\n",
    "Let's build on this and see how we can create a DataFrame where we calculate the mean temperatures in Celsius and Fahrenheit. We will repeat some of the earlier steps here so you can see and better understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for the aggregated values\n",
    "\n",
    "\n",
    "# The columns that we want to aggregate\n",
    "mean_cols = [\"TEMP_F\", \"TEMP_C\"]\n",
    "\n",
    "# Iterate over the groups\n",
    "\n",
    "\n",
    "    # Calculate mean\n",
    "    \n",
    "\n",
    "    # Add the ´key´ (i.e. the date+time information) into the aggregated values\n",
    "    \n",
    "    \n",
    "    # Convert the mean_values series to a DataFrame and make it have a row orientation\n",
    "    \n",
    "\n",
    "    # Concatenate the aggregated values into the daily_data DataFrame\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **ℹ️ Why do we use `.transpose()` here?**  \n",
    ">\n",
    "> When we calculate the mean for each group, the result is a **Series**.  \n",
    "> Converting it with `.to_frame()` gives a **vertical column**:\n",
    ">\n",
    "> ```\n",
    ">           0\n",
    "> TEMP_F   71.2\n",
    "> TEMP_C   21.8\n",
    "> MONTH_DAY 03-07\n",
    "> ```\n",
    ">\n",
    "> But what we want is a **row** in our results table.  \n",
    "> Using `.transpose()` flips it sideways into the correct format:\n",
    ">\n",
    "> ```\n",
    "> TEMP_F   TEMP_C   MONTH_DAY\n",
    "> 71.2     21.8     03-07\n",
    "> ```\n",
    ">\n",
    "> This way, each group’s means can be concatenated cleanly into the\n",
    "> `daily_data` DataFrame.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can find a slightly more efficient approach for this same kind of aggregation in [Chapter 3 of the *Python for Geographic Data Analysis* textbook](https://pythongis.org/part1/chapter-03/nb/02-data-analysis.html#aggregating-data-with-groupby).\n",
    "\n",
    "Now, let us see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have aggregated our data and we have a new DataFrame called `daily_data` where we have mean values for each day in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting warm days in July\n",
    "\n",
    "Now that we have aggregated our data on daily level, we want to sort our results in order to check which days in July had the warmest temperatures on average. A simple approach is to select all the data rows from July and then group the data and check which group(s) (days in our case) have the highest mean value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can take a subset of columns that might contain interesting information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "July_days = July_days[[\"TEMP_F\", \"TEMP_C\", \"MONTH_DAY\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group by month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can calculate the mean for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can sort and check the highest temperature values. We can sort the data frame in a descending order to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what were the warmest days in July?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Did we break the record in Helsinki?\n",
    "\n",
    "While the average temperature provides a general sense of how warm the days typically are, the news article about record-breaking heat was based on the highest recorded temperature of the day. Now, we will redo the grouping of the data by day for the whole summer, but instead of calculating the mean temperature, we will calculate the maximum recorded temperature for each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all days and leep only two columns\n",
    "summer_days = data[[\"TEMP_C\", \"MONTH_DAY\"]]\n",
    "\n",
    "# Group data based by days\n",
    "grouped = summer_days.groupby(by=\"MONTH_DAY\")\n",
    "\n",
    "# Calculate the daily maximum temperature\n",
    "daily_max = grouped.max()\n",
    "\n",
    "# Rename the column TEMP_C to MAX_C for better clarity\n",
    "daily_max = daily_max.rename(columns={\"TEMP_C\": \"MAX_C\"})\n",
    "\n",
    "# View the first five rows of output data\n",
    "daily_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's count the number of hot days (>= 25 degrees celsius) in Helsinki and see whether the country record was also broken in Helsinki or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it your self\n",
    "count_hot_days = len(daily_max[daily_max[\"MAX_C\"] >= 25])\n",
    "print(f\"In the summer of 2024, there were {count_hot_days} days with temperatures exceeding 25°C.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Repeating the data analysis with a larger dataset\n",
    "\n",
    "To wrap up today's lesson, let's repeat the data analysis steps above for all the available data we have (!). Of course we want to automate this process and not repeate the process for each dataset. \n",
    "\n",
    "The idea is, that we will repeat the analysis process for each input file using a (rather long) for loop! Here we have all the main analysis steps with some additional output info, all in one long code cell.\n",
    "\n",
    "At this point we will use the `.glob()` function from the module `glob` to list our input files. glob is a handy function for finding files in a directrory that match a given pattern, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Note**: We're using the \\* character as a wildcard, so any file that starts with `data/` and ends with `csv` will be added to the list of files we will iterate over. In our case there are not other data files in this directory. But this can be specifically useful if there are other files in the folder which we do not want to include in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of files in the list: {len(file_list)}\")\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should have all the relevant file names in a list, and we can loop over the list using a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in file_list:\n",
    "    print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "And here is our `for` loop to repeat the calculation for all our data from the different stations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Repeat the analysis steps for each input file:\n",
    "for fp in file_list:\n",
    "    \n",
    "    # read the data, some datasets have missing values filled as \"-\"\n",
    "    data = pd.read_csv(\n",
    "        fp,\n",
    "        usecols=['Observation station', 'Year', 'Month', 'Day','Time [Local time]', 'Air temperature mean [°C]'], na_values=[\"-\"])\n",
    "    \n",
    "    # Create the dictionary with old and new names\n",
    "    new_names = {\"Observation station\": \"STATION\", \"Time [Local time]\": \"TIME\", \"Air temperature mean [°C]\": \"TEMP_C\"}\n",
    "    \n",
    "    # Rename the columns\n",
    "    data = data.rename(columns=new_names)\n",
    "    \n",
    "    # Convert to string\n",
    "    data[\"MONTH_STR\"] = data[\"Month\"].astype(str)\n",
    "    data[\"DAY_STR\"] = data[\"Day\"].astype(str)\n",
    "    \n",
    "    # Combine the two strings\n",
    "    data[\"MONTH_DAY\"] = data[\"MONTH_STR\"].str.zfill(2) + \"-\" + data[\"DAY_STR\"].str.zfill(2)\n",
    "    \n",
    "    # Select all days and leep only two columns\n",
    "    summer_days = data[[\"TEMP_C\", \"MONTH_DAY\"]]\n",
    "    \n",
    "    # Group data based by days\n",
    "    grouped = summer_days.groupby(by=\"MONTH_DAY\")\n",
    "    \n",
    "    # Calculate the daily maximum temperature\n",
    "    daily_max = grouped.max()\n",
    "\n",
    "    # Rename the column TEMP_C to MAX_C for better clarity\n",
    "    daily_max = daily_max.rename(columns={\"TEMP_C\": \"MAX_C\"})\n",
    "    \n",
    "    count_hot_days = len(daily_max[daily_max[\"MAX_C\"] >= 25])\n",
    "    \n",
    "    # Extract station name from fp - the part of the string between 'data/' and '.csv'\n",
    "    station_name = fp.replace(\"\\\\\", \"/\").split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "    \n",
    "    print(f\"In the summer of 2024, there were {count_hot_days} days with temperatures exceeding 25°C in {station_name}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what can we conclude about record breaking hot days in Summer 2024 in Finland?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
